# server
quarkus.http.http2=true
quarkus.http.access-log.enabled=true
quarkus.http.access-log.pattern=%{REMOTE_HOST} %l %{REMOTE_USER} %{DATE_TIME} "%{REQUEST_LINE}" %{RESPONSE_CODE} %b %{RESPONSE_TIME}
quarkus.http.record-request-start-time=true
# rest client
quarkus.rest-client.http2=true
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
# azure AI
quarkus.langchain4j.azure-openai.api-key=mykey
quarkus.langchain4j.azure-openai.resource-name=env_file
# for all models - don't works
#quarkus.langchain4j.azure-openai.domain-name=azure-api.net
# for each one model - works
quarkus.langchain4j.azure-openai.chat-model.domain-name=azure-api.net
quarkus.langchain4j.azure-openai.embedding-model.domain-name=azure-api.net
quarkus.langchain4j.azure-openai.image-model.domain-name=azure-api.net
# embed 1536
quarkus.langchain4j.azure-openai.embedding-model.deployment-name=opl-usersandbox-open-ai-automated-deployment
quarkus.langchain4j.azure-openai.embedding-model.max-tokens=120000
quarkus.langchain4j.azure-openai.embedding-model.api-version=2023-05-15
quarkus.langchain4j.azure-openai.deployment-name=gpt-35-turbo
quarkus.langchain4j.azure-openai.chat-model=gpt-35-turbo
quarkus.langchain4j.azure-openai.api-version=2024-02-15-preview
quarkus.langchain4j.azure-openai.log-requests=true
quarkus.langchain4j.azure-openai.log-responses=true
# 1.0
quarkus.langchain4j.azure-openai.chat-model.temperature=0.2
# 1.0
quarkus.langchain4j.azure-openai.chat-model.top-p=0.1
# qdrant
quarkus.langchain4j.qdrant.host=localhost
quarkus.langchain4j.qdrant.collection.name=demo-test
# easy rag
quarkus.langchain4j.easy-rag.path=src/main/resources/documents
quarkus.langchain4j.easy-rag.max-segment-size=300
quarkus.langchain4j.easy-rag.max-overlap-size=30
quarkus.langchain4j.easy-rag.max-results=5
quarkus.langchain4j.easy-rag.path-matcher=glob:**
# build
quarkus.native.additional-build-args=--initialize-at-run-time=io.grpc.netty.shaded.io.netty.util.internal.logging.Log4JLogger